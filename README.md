# ğŸ¤ VoiceShield - Production-Ready Voice Detection System

A complete full-stack application for AI-generated voice detection using MERN stack + FastAPI ML backend.

## ğŸ—ï¸ Architecture

```
VoiceShield/
â”œâ”€â”€ Frontend (React.js)        â†’ http://localhost:3000
â”œâ”€â”€ Backend (Node.js/Express)  â†’ http://localhost:5000
â””â”€â”€ ML Service (FastAPI)       â†’ http://localhost:8000
```

## ğŸš€ Quick Start

### Prerequisites
- Node.js 16+ and npm
- Python 3.10+
- Git

### 1ï¸âƒ£ Start ML Service (FastAPI)

```powershell
cd "d:\MINI project\ml-service"
python run_web.py
```

**Expected Output:**
```
Uvicorn running on http://0.0.0.0:8000
```

### 2ï¸âƒ£ Start Backend Server (Express)

```powershell
cd "d:\MINI project\Backend"
npm install  # (only first time)
node server.js
```

**Expected Output:**
```
ğŸ™ï¸ VoiceShield Backend running on http://0.0.0.0:5000
ğŸ“¡ ML Service expected at http://localhost:8000
```

### 3ï¸âƒ£ Start Frontend (React)

```powershell
cd "d:\MINI project\Front end"
npm install  # (only first time)
npm run dev
```

**Expected Output:**
```
VITE v5.4.21  ready in XXX ms
âœ  Local:   http://localhost:3000/
```

## ğŸŒ Access the Application

Once all three services are running:
- **Frontend UI:** http://localhost:3000
- **Backend API:** http://localhost:5000/api/audio/health
- **ML Service:** http://localhost:8000/health

## ğŸ“‹ Features

### Frontend
- âœ… Drag & drop audio file upload
- âœ… Audio preview with player controls  
- âœ… Real-time prediction display
- âœ… Confidence score visualization
- âœ… Scrollable history panel
- âœ… localStorage persistence
- âœ… Responsive design
- âœ… Loading animations

### Backend
- âœ… Express.js REST API
- âœ… Multer file upload handling (50MB limit)
- âœ… CORS enabled for frontend
- âœ… Error handling and validation
- âœ… Temporary file cleanup
- âœ… Health check endpoints

### ML Service (FastAPI)
- âœ… One-Class ML model for voice authenticity
- âœ… MFCC + spectral feature extraction
- âœ… Audio preprocessing
- âœ… JSON REST API
- âœ… Confidence scoring

## ğŸ”„ Data Flow

```
Frontend (React)
    â†“ (file upload)
Backend (Express/Multer)
    â†“ (forward to ML)
ML Service (FastAPI)
    â†“ (feature extraction + inference)
Backend (Express)
    â†“ (add metadata + history)
Frontend (React)
    â†“ (display result + save to localStorage)
```

## ğŸ“ Project Structure

```
d:\MINI project\
â”œâ”€â”€ Frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioUpload.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioHistory.jsx
â”‚   â”‚   â”‚   â””â”€â”€ ResultDisplay.jsx
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â”œâ”€â”€ App.css
â”‚   â”‚   â”œâ”€â”€ index.css
â”‚   â”‚   â””â”€â”€ main.jsx
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ node_modules/
â”‚
â”œâ”€â”€ Backend/
â”‚   â”œâ”€â”€ server.js
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ audio.js
â”‚   â”œâ”€â”€ uploads/  (temp files)
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ node_modules/
â”‚
â””â”€â”€ ml-service/ (FastAPI)
    â”œâ”€â”€ app.py
    â”œâ”€â”€ run_web.py
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ predict.py
    â”‚   â”œâ”€â”€ preprocess.py
    â”‚   â”œâ”€â”€ extract_features.py
    â”‚   â””â”€â”€ train_model.py
    â”œâ”€â”€ models/
    â”‚   â””â”€â”€ voice_model.pkl
    â”œâ”€â”€ data/
    â””â”€â”€ requirements.txt
```

## ğŸ› ï¸ API Endpoints

### Backend Endpoints

**Predict Voice**
```http
POST /api/audio/predict
Content-Type: multipart/form-data

Body: { file: <audio_file> }

Response:
{
  "success": true,
  "prediction": "REAL" | "FAKE",
  "confidence": 85,
  "fileName": "sample.wav",
  "uploadedAt": "2026-02-03T12:00:00Z"
}
```

**Health Check**
```http
GET /api/audio/health

Response:
{
  "backend": "ok",
  "ml_service": "ok",
  "ml_model_loaded": true
}
```

## ğŸ¨ UI Components

### AudioUpload
- Drag & drop zone
- File input selector
- Supported formats display

### ResultDisplay
- Prediction badge (REAL/FAKE)
- Confidence score with progress bar
- File metadata
- Timestamp
- Descriptive message

### AudioHistory
- Scrollable list of past predictions
- Quick access to previous results
- Clear history button
- Selection highlighting

## ğŸ” Security Features

- âœ… File type validation (audio only)
- âœ… File size limits (50MB max)
- âœ… CORS protection
- âœ… Temporary file cleanup
- âœ… Error handling without stack traces in production

## ğŸ“Š Technology Stack

| Layer | Technology |
|-------|------------|
| Frontend | React 18 + Vite + CSS3 |
| Backend | Node.js + Express + Multer |
| ML | FastAPI + Scikit-learn + Librosa |
| Storage | localStorage (frontend) |
| File Upload | Multer |

## ğŸ› Troubleshooting

### ML Service fails to start
```bash
pip install -r requirements.txt
python run_web.py
```

### Backend can't connect to ML Service
- Ensure ML Service is running on port 8000
- Check firewall settings
- Verify environment variable: ML_SERVICE_URL=http://localhost:8000

### Frontend shows "Can't connect"
- Verify Backend is running on port 5000
- Check CORS is enabled
- Clear browser cache (Ctrl+Shift+Delete)

### App.css not found error
- Delete `Frontend/node_modules`
- Run `npm install` again
- Restart `npm run dev`

## ğŸ“ˆ Performance

- Frontend: ~100-200ms render
- Upload: Supports up to 50MB
- Processing: 2-5 seconds per audio file
- History: Stores 50 latest predictions (localStorage)

## ğŸ”„ Development Workflow

1. **Frontend Development**
   ```bash
   cd Frontend
   npm run dev  # Hot reload enabled
   ```

2. **Backend Development**
   ```bash
   cd Backend
   npm install nodemon -g  # Global
   npm run dev  # Auto-restart on changes
   ```

3. **ML Development**
   ```bash
   cd ml-service
   python run_pipeline.py data  # Train model
   python run_web.py            # Start API
   ```

## ğŸ“ Environment Variables

### Backend (.env)
```
PORT=5000
NODE_ENV=development
ML_SERVICE_URL=http://localhost:8000
```

## ğŸš€ Production Deployment

### Frontend (Vercel/Netlify)
```bash
npm run build
# Upload dist/ folder
```

### Backend (Heroku/Railway)
```bash
npm install
npm start
```

### ML Service (AWS/GCP)
- Use Uvicorn + Gunicorn
- Set PYTHONUNBUFFERED=1
- Ensure model.pkl is available

## ğŸ“„ License

MIT License - Free to use and modify

## ğŸ‘¥ Support

For issues or questions, check the deployment terminals and logs.

---

**Built with â¤ï¸ for voice authenticity detection**
